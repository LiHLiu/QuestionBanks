{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1733f9a",
   "metadata": {},
   "source": [
    "# 使用 LangChain 示例\n",
    "sk-c64994ca9f9741888dc7bccdef2aa0a1\n",
    "\n",
    "### 1. 获取 API key 并创建调用 API 的函数\n",
    "\n",
    "首先使用`pip install dashscope`安装阿里云百炼的 Python SDK\n",
    "\n",
    "然后导入相关依赖包，使用`getpass`输入api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff691491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from dashscope import Generation\n",
    "import os\n",
    "# 安全获取API Key（输入时不显示明文）\n",
    "api_key = getpass(\"请输入阿里云百炼API Key: \")\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = api_key\n",
    "Generation.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e58f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_qwen(prompt=\"请介绍一下通义千问模型\", model=\"qwen-turbo\"):\n",
    "    \"\"\"\n",
    "    调用通义千问模型获取回答\n",
    "\n",
    "    Args:\n",
    "        prompt: 用户输入的问题\n",
    "        model: 使用的模型名称，默认为\"qwen-turbo\"\n",
    "\n",
    "    Returns:\n",
    "        模型生成的回答内容\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 调用模型生成文本（单轮对话用prompt参数）\n",
    "        response = Generation.call(\n",
    "            model=\"qwen-turbo\",  # 指定模型\n",
    "            prompt=prompt,  # 单轮对话使用prompt\n",
    "            api_key=api_key  # 使用环境变量中的API Key\n",
    "        )\n",
    "\n",
    "        # 解析响应（output是字典，用[\"text\"]获取内容）\n",
    "        if response.status_code == 200:\n",
    "            return response.output[\"text\"]  # 修正解析方式\n",
    "        else:\n",
    "            return f\"请求失败，状态码: {response.status_code}，原因: {response.message}\"\n",
    "    except Exception as e:\n",
    "        return f\"调用出错: {str(e)}\"\n",
    "\n",
    "# 测试调用\n",
    "print(call_qwen(\"通义千问模型的特点是什么？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6210f",
   "metadata": {},
   "source": [
    "### 后端接口设计\n",
    "\n",
    "- 导入本地文件\n",
    "- 根据主题检索知识库文段\n",
    "- 文段导入大模型生成QA问答\n",
    "  - 单个文段导入大模型\n",
    "  - 循环生成\n",
    "- 处理生成的QA问答实现数据格式化\n",
    "- 保存生成的题库至本地\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df69502",
   "metadata": {},
   "outputs": [],
   "source": [
    "###导入本地文件函数\n",
    "def import_local_file(file_path):\n",
    "    \"\"\"\n",
    "    导入本地文件内容\n",
    "\n",
    "    Args:\n",
    "        file_path: 本地文件路径\n",
    "\n",
    "    Returns:\n",
    "        文件内容字符串\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e1ef9",
   "metadata": {},
   "source": [
    "### 2. 使用 LangChain 调用通义千问模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43384d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "# from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c2d1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "llm = Tongyi(\n",
    "    model=\"qwen-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "question = \"什么是人工智能？\"\n",
    "\n",
    "# 创建提示模板\n",
    "template = \"\"\"\n",
    "你是一个有用的助手。请回答以下问题：\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# 创建链\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1ceef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '什么是人工智能？', 'text': '人工智能（Artificial Intelligence，简称AI）是指由人创造的能够模拟人类智能行为的系统或机器。它可以通过学习、推理、感知、语言理解和问题解决等能力，完成一些通常需要人类智能才能完成的任务。\\n\\n人工智能可以分为两大类：\\n\\n1. **弱人工智能（Narrow AI）**：专注于执行特定任务，如语音识别、图像识别、推荐系统等。目前大多数实际应用都属于这一类，例如智能手机中的语音助手、搜索引擎和自动驾驶技术。\\n\\n2. **强人工智能（General AI）**：具备与人类相当的广泛认知能力，可以理解、学习和执行任何智力任务。目前尚未实现，仍处于研究阶段。\\n\\n人工智能的核心技术包括机器学习、深度学习、自然语言处理、计算机视觉和专家系统等。它在医疗、金融、交通、教育、娱乐等多个领域都有广泛应用。'}\n"
     ]
    }
   ],
   "source": [
    "# 调用模型\n",
    "question = \"什么是人工智能？\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe16c6",
   "metadata": {},
   "source": [
    "### 3. 使用 faiss 构建RAG检索\n",
    "\n",
    "使用`pip install pypdf faiss-cpu`安装依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3e006a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "### 加载PDF文档\n",
    "# loader = PyPDFLoader(\"./data/sample.pdf\")\n",
    "# pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870330f",
   "metadata": {},
   "source": [
    "### 4. 将生成的题库保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e87c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载的题目： 线性回归的目标是最小化什么损失？\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 定义保存路径\n",
    "SAVE_DIR = \"./question_banks\"\n",
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)  # 确保文件夹存在\n",
    "\n",
    "# 2. 生成单题数据\n",
    "def create_question(stem, type_, answer, **kwargs):\n",
    "    return {\n",
    "        \"question_id\": str(uuid.uuid4()),  # 自动生成唯一ID\n",
    "        \"stem\": stem,\n",
    "        \"type\": type_,\n",
    "        \"answer\": answer,\n",
    "        \"options\": kwargs.get(\"options\", []),\n",
    "        \"explanation\": kwargs.get(\"explanation\", \"\"),\n",
    "        \"difficulty\": kwargs.get(\"difficulty\", \"medium\"),\n",
    "        \"keywords\": kwargs.get(\"keywords\", []),\n",
    "        \"source\": kwargs.get(\"source\", \"\"),\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"updated_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "# 3. 保存题库到JSON\n",
    "def save_bank_to_json(bank_name, questions, description=\"\"):\n",
    "    bank = {\n",
    "        \"bank_id\": f\"{bank_name.replace(' ', '_').lower()}_bank\",\n",
    "        \"name\": bank_name,\n",
    "        \"description\": description,\n",
    "        \"questions\": questions,\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"updated_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    file_path = os.path.join(SAVE_DIR, f\"{bank_name}.json\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(bank, f, ensure_ascii=False, indent=2)  # 缩进2空格，可读性强\n",
    "    return file_path\n",
    "\n",
    "# 4. 从JSON加载题库（用于刷题调用）\n",
    "def load_bank_from_json(bank_name):\n",
    "    file_path = os.path.join(SAVE_DIR, f\"{bank_name}.json\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 示例：生成并保存一个题库\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建2道题\n",
    "    q1 = create_question(\n",
    "        stem=\"线性回归的目标是最小化什么损失？\",\n",
    "        type_=\"single_choice\",\n",
    "        answer=\"A\",\n",
    "        options=[\"平方损失\", \"交叉熵损失\", \"绝对值损失\"],\n",
    "        difficulty=\"easy\",\n",
    "        keywords=[\"线性回归\", \"损失函数\"],\n",
    "        source=\"机器学习入门.pdf\"\n",
    "    )\n",
    "    # 保存题库\n",
    "    save_bank_to_json(\"机器学习基础题库\", [q1])\n",
    "    # 加载题库（刷题时用）\n",
    "    bank = load_bank_from_json(\"机器学习基础题库\")\n",
    "    print(\"加载的题目：\", bank[\"questions\"][0][\"stem\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40b001",
   "metadata": {},
   "source": [
    "### 5. 使用 gradio 实现前端界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90680049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7885\n",
      "\n",
      "Could not create share link. Missing file: d:\\anaconda\\envs\\chatgpt\\lib\\site-packages\\gradio\\frpc_windows_amd64_v0.2. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_windows_amd64.exe\n",
      "2. Rename the downloaded file to: frpc_windows_amd64_v0.2\n",
      "3. Move the file to this location: d:\\anaconda\\envs\\chatgpt\\lib\\site-packages\\gradio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7885/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "# 创建Gradio聊天界面\n",
    "demo = gr.ChatInterface(\n",
    "    fn=call_qwen,  # 传入函数对象，而非调用结果\n",
    "    title=\"通义千问对话助手\",\n",
    "    description=\"与通义千问模型进行对话，支持多轮交流\"\n",
    "    \n",
    ")\n",
    "\n",
    "# 启动界面\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
