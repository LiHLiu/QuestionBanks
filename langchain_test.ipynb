{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1733f9a",
   "metadata": {},
   "source": [
    "# 使用 LangChain 示例\n",
    "sk-c64994ca9f9741888dc7bccdef2aa0a1\n",
    "\n",
    "### 1. 获取 API key 并创建调用 API 的函数\n",
    "\n",
    "首先使用`pip install dashscope`安装阿里云百炼的 Python SDK\n",
    "\n",
    "然后导入相关依赖包，使用`getpass`输入api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff691491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from dashscope import Generation\n",
    "import os\n",
    "# 安全获取API Key（输入时不显示明文）\n",
    "api_key = getpass(\"请输入阿里云百炼API Key: \")\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = api_key\n",
    "Generation.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e58f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "通义千问（Qwen）是通义实验室研发的超大规模语言模型，具有以下特点：\n",
      "\n",
      "1. **强大的语言理解与生成能力**：通义千问能够理解和生成多种语言的文本，支持多轮对话、文本续写、问答等多种任务。\n",
      "\n",
      "2. **广泛的知识覆盖**：模型在训练过程中学习了大量文本数据，因此在多个领域都有较深的知识积累，可以回答各种问题。\n",
      "\n",
      "3. **多语言支持**：除了中文，通义千问还支持英文、法语、西班牙语、葡萄牙语、俄语、日语、韩语等十余种语言。\n",
      "\n",
      "4. **良好的对话表现**：通义千问在对话中能够保持上下文连贯，理解用户意图，并提供自然流畅的回复。\n",
      "\n",
      "5. **可定制化**：用户可以根据具体需求对模型进行微调，以适应特定的应用场景。\n",
      "\n",
      "6. **高性能**：通义千问在多个基准测试中表现出色，如GLUE、SuperGLUE、MMLU等，展示了其强大的性能。\n",
      "\n",
      "7. **安全与合规**：通义千问在设计和训练过程中注重安全性和合规性，能够识别并避免生成违法不良信息。\n",
      "\n",
      "8. **开源与商业应用**：通义千问提供了多种版本，包括开源版本和商业版本，满足不同用户的需求。\n",
      "\n",
      "总之，通义千问是一个功能强大、应用广泛的大型语言模型，适用于多种场景和任务。\n"
     ]
    }
   ],
   "source": [
    "def call_qwen(prompt=\"请介绍一下通义千问模型\", model=\"qwen-turbo\"):\n",
    "    \"\"\"\n",
    "    调用通义千问模型获取回答\n",
    "\n",
    "    Args:\n",
    "        prompt: 用户输入的问题\n",
    "        model: 使用的模型名称，默认为\"qwen-turbo\"\n",
    "\n",
    "    Returns:\n",
    "        模型生成的回答内容\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 调用模型生成文本（单轮对话用prompt参数）\n",
    "        response = Generation.call(\n",
    "            model=\"qwen-turbo\",  # 指定模型\n",
    "            prompt=prompt,  # 单轮对话使用prompt\n",
    "            api_key=api_key  # 使用环境变量中的API Key\n",
    "        )\n",
    "\n",
    "        # 解析响应（output是字典，用[\"text\"]获取内容）\n",
    "        if response.status_code == 200:\n",
    "            return response.output[\"text\"]  # 修正解析方式\n",
    "        else:\n",
    "            return f\"请求失败，状态码: {response.status_code}，原因: {response.message}\"\n",
    "    except Exception as e:\n",
    "        return f\"调用出错: {str(e)}\"\n",
    "\n",
    "# 测试调用\n",
    "print(call_qwen(\"通义千问模型的特点是什么？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6210f",
   "metadata": {},
   "source": [
    "### 后端接口设计\n",
    "\n",
    "- 导入本地文件\n",
    "  - .txt\n",
    "  - .md\n",
    "  - .pdf\n",
    "- 根据主题检索知识库文段\n",
    "- 文段导入大模型生成QA问答\n",
    "  - 单个文段导入大模型\n",
    "  - 循环生成\n",
    "- 处理生成的QA问答实现数据格式化\n",
    "- 保存生成的题库至本地\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df69502",
   "metadata": {},
   "outputs": [],
   "source": [
    "###导入本地文件函数\n",
    "def import_local_file(file_path):\n",
    "    \"\"\"\n",
    "    导入本地文件内容\n",
    "\n",
    "    Args:\n",
    "        file_path: 本地文件路径\n",
    "\n",
    "    Returns:\n",
    "        成功导入文件内容或错误信息\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91d201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e1ef9",
   "metadata": {},
   "source": [
    "### 2. 使用 LangChain 调用通义千问模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43384d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "# from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2d1261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12066\\AppData\\Local\\Temp\\ipykernel_18952\\3351139764.py:26: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "llm = Tongyi(\n",
    "    model=\"qwen-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "question = \"什么是人工智能？\"\n",
    "\n",
    "# 创建提示模板\n",
    "template = \"\"\"\n",
    "你是一个有用的助手。请回答以下问题：\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# 创建链\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ceef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '什么是人工智能？', 'text': '人工智能（Artificial Intelligence，简称AI）是指由人创造的能够模拟人类智能行为的系统或机器。它可以通过学习、推理、感知、语言理解、问题解决等能力，完成一些通常需要人类智慧才能完成的任务。\\n\\n人工智能可以分为两大类：\\n\\n1. **弱人工智能（Narrow AI）**：专注于执行特定任务，如语音识别、图像识别、推荐系统等。目前大多数实际应用都属于这一类，例如语音助手（如Siri）、人脸识别系统等。\\n\\n2. **强人工智能（General AI）**：具备与人类相当的全面认知能力，能够理解、学习和应用知识到各种不同领域。目前尚未实现，仍处于研究阶段。\\n\\n人工智能的核心技术包括机器学习、深度学习、自然语言处理、计算机视觉、机器人技术等。它广泛应用于医疗、金融、交通、教育、娱乐等多个领域，正在深刻改变我们的生活和工作方式。'}\n"
     ]
    }
   ],
   "source": [
    "# 调用模型\n",
    "question = \"什么是人工智能？\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe16c6",
   "metadata": {},
   "source": [
    "### 3. 使用 faiss 构建RAG检索\n",
    "\n",
    "使用`pip install pypdf faiss-cpu`安装依赖包\n",
    "\n",
    "#### 3.1 初步创建向量数据库，根据所选文件进行切分和向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3e006a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.embeddings import DashScopeEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = api_key\n",
    "\n",
    "def create_vector_store(file_path):\n",
    "\n",
    "    if file_path.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        loader = TextLoader(file_path, encoding='utf-8')\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的文件类型: {file_path}\")\n",
    "\n",
    "    pages = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "\n",
    "    # 创建通义千问embeddings\n",
    "    embeddings = DashScopeEmbeddings(\n",
    "        model=\"text-embedding-v1\"\n",
    "    )\n",
    "\n",
    "    vector_store = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "    print(f\"成功创建RAG向量数据库，共处理 {len(docs)} 个文档片段\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d04ff3",
   "metadata": {},
   "source": [
    "#### 3.2 加载已有的向量数据库并添加新文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_new_documents(file_path):\n",
    "    embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "    vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    if file_path.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        loader = TextLoader(file_path, encoding='utf-8')\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的文件类型: {file_path}\")\n",
    "    \n",
    "    documents = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_new_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f7d46",
   "metadata": {},
   "source": [
    "#### 3.3 根据关键词检索数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43305d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询: 延长学制\n",
      "找到 3 个相关文档:\n",
      "\n",
      "--- 文档 1 ---\n",
      "内容: — 13 —\n",
      "阶段）；临床医学八年制本博连读生的博士研究生阶段基本修业\n",
      "年限为4 年。\n",
      "基本修业年限由各学科专业在本办法规定的年限内予以明\n",
      "确。“强基计划”等本研贯通项目录取转段的研究生基本修业年\n",
      "限要求依据相关项目培养规定确定。\n",
      "第二十八条 研究生在基本修业年限内不能完成学业的，可\n",
      "申请延长修业年限（以下简称延期）。全日制博士研究生最长修\n",
      "业年限为在原基本修业年限基础上延长 2 年；全日制硕士研...\n",
      "来源: ./data/sample.pdf\n",
      "页码: 12\n",
      "--------------------------------------------------\n",
      "--- 文档 2 ---\n",
      "内容: — 22 —\n",
      "包括本数；所称的“不满”“超过”，不包括本数。\n",
      "第五十六条 本办法由研究生院负责解释。\n",
      "第五十七条 本办法自发布之日起施行，《浙江大学研究生\n",
      "学籍管理实施办法》（浙大发研〔2017〕115 号）同时废止。本\n",
      "办法实施之前已入学的研究生，可以继续适用原办法。\n",
      "抄送：纪委，各院级党委，党委各部门，各党工委，工会、团委。\n",
      "浙江大学校长办公室 主动公开 2024 年8 月16 日印发...\n",
      "来源: ./data/sample.pdf\n",
      "页码: 21\n",
      "--------------------------------------------------\n",
      "--- 文档 3 ---\n",
      "内容: — 2 —\n",
      "浙江大学研究生学籍管理实施办法\n",
      "第一章 总 则\n",
      "第一条 为全面贯彻国家教育方针，规范研究生学籍管理，\n",
      "维护研究生正常教育教学秩序，保障研究生身心健康与合法权\n",
      "益，促进研究生全面发展，依据教育部《普通高等学校学生管理\n",
      "规定》（中华人民共和国教育部令第 41 号），制定本办法。\n",
      "第二条 本办法适用于学校对接受普通高等学历教育的研\n",
      "究生的管理。\n",
      "第二章 新生入学\n",
      "第三条 研究生新生应当在学校...\n",
      "来源: ./data/sample.pdf\n",
      "页码: 1\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def search_similar_documents(query, k=4):\n",
    "    \"\"\"\n",
    "    根据查询词搜索相似文档\n",
    "    query: 查询关键词或句子\n",
    "    k: 返回最相似的k个结果\n",
    "    \"\"\"\n",
    "    embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "    vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    similar_docs = vector_store.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"查询: {query}\")\n",
    "    print(f\"找到 {len(similar_docs)} 个相关文档:\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(similar_docs):\n",
    "        print(f\"--- 文档 {i+1} ---\")\n",
    "        print(f\"内容: {doc.page_content[:200]}...\")\n",
    "        print(f\"来源: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"页码: {doc.metadata.get('page', 'N/A')}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return similar_docs\n",
    "\n",
    "# 使用示例\n",
    "query = \"延长学制\"\n",
    "results = search_similar_documents(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870330f",
   "metadata": {},
   "source": [
    "### 4. 将生成的题库保存到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e87c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载的题目： 线性回归的目标是最小化什么损失？\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 定义保存路径\n",
    "SAVE_DIR = \"./question_banks\"\n",
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)  # 确保文件夹存在\n",
    "\n",
    "# 2. 生成单题数据\n",
    "def create_question(stem, type_, answer, **kwargs):\n",
    "    return {\n",
    "        \"question_id\": str(uuid.uuid4()),  # 自动生成唯一ID\n",
    "        \"stem\": stem,\n",
    "        \"type\": type_,\n",
    "        \"answer\": answer,\n",
    "        \"options\": kwargs.get(\"options\", []),\n",
    "        \"explanation\": kwargs.get(\"explanation\", \"\"),\n",
    "        \"difficulty\": kwargs.get(\"difficulty\", \"medium\"),\n",
    "        \"keywords\": kwargs.get(\"keywords\", []),\n",
    "        \"source\": kwargs.get(\"source\", \"\"),\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"updated_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "# 3. 保存题库到JSON\n",
    "def save_bank_to_json(bank_name, questions, description=\"\"):\n",
    "    bank = {\n",
    "        \"bank_id\": f\"{bank_name.replace(' ', '_').lower()}_bank\",\n",
    "        \"name\": bank_name,\n",
    "        \"description\": description,\n",
    "        \"questions\": questions,\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"updated_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    file_path = os.path.join(SAVE_DIR, f\"{bank_name}.json\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(bank, f, ensure_ascii=False, indent=2)  # 缩进2空格，可读性强\n",
    "    return file_path\n",
    "\n",
    "# 4. 从JSON加载题库（用于刷题调用）\n",
    "def load_bank_from_json(bank_name):\n",
    "    file_path = os.path.join(SAVE_DIR, f\"{bank_name}.json\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 示例：生成并保存一个题库\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建2道题\n",
    "    q1 = create_question(\n",
    "        stem=\"线性回归的目标是最小化什么损失？\",\n",
    "        type_=\"single_choice\",\n",
    "        answer=\"A\",\n",
    "        options=[\"平方损失\", \"交叉熵损失\", \"绝对值损失\"],\n",
    "        difficulty=\"easy\",\n",
    "        keywords=[\"线性回归\", \"损失函数\"],\n",
    "        source=\"机器学习入门.pdf\"\n",
    "    )\n",
    "    # 保存题库\n",
    "    save_bank_to_json(\"机器学习基础题库\", [q1])\n",
    "    # 加载题库（刷题时用）\n",
    "    bank = load_bank_from_json(\"机器学习基础题库\")\n",
    "    print(\"加载的题目：\", bank[\"questions\"][0][\"stem\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40b001",
   "metadata": {},
   "source": [
    "### 5. 使用 gradio 实现前端界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90680049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Missing file: d:\\anaconda\\envs\\chatgpt\\lib\\site-packages\\gradio\\frpc_windows_amd64_v0.2. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_windows_amd64.exe\n",
      "2. Rename the downloaded file to: frpc_windows_amd64_v0.2\n",
      "3. Move the file to this location: d:\\anaconda\\envs\\chatgpt\\lib\\site-packages\\gradio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "# 创建Gradio聊天界面\n",
    "demo = gr.ChatInterface(\n",
    "    fn=call_qwen,  # 传入函数对象，而非调用结果\n",
    "    title=\"通义千问对话助手\",\n",
    "    description=\"与通义千问模型进行对话，支持多轮交流\"\n",
    "    \n",
    ")\n",
    "\n",
    "# 启动界面\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
